{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91de3ea5",
   "metadata": {},
   "source": [
    "# Select top-N assets with good indicators\n",
    "The objective is to calculate the standard indicators for a top N number of assets. Then use the indicators to decide on a potentially significant set of assets to consider for the portfolio. Thereafter, apply the MPT monte carlo algorithm to construct a weigted portfolio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3215d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    WARNING CONTROL to display or ignore all warnings\n",
    "'''\n",
    "import warnings; warnings.simplefilter('ignore') #switch betweeb 'default' and 'ignore'\n",
    "import traceback\n",
    "\n",
    "''' Set debug flag to view extended error messages; \n",
    "    else set it to False to turn off debugging mode '''\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e5085",
   "metadata": {},
   "source": [
    "## Initialize the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67d1a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functional APP-libraries in REZAWARE-package of REZAWARE-module imported successfully!\n",
      "All functional PERFORMINDEX-libraries in ETP-package of ASSETS-module imported successfully!\n",
      "All functional SPARKDBWLS-libraries in LOAD-package of ETL-module imported successfully!\n",
      "All packages in utils ml timeseries RollingStats imported successfully!\n",
      "All functional SPARKNOSQLWLS-libraries in LOAD-package of ETL-module imported successfully!\n",
      "All functional EXECSESSION-libraries in SPARK-package of LIB-module imported successfully!\n",
      "All functional APP-libraries in REZAWARE-package of REZAWARE-module imported successfully!\n",
      "All functional PERFORMINDEX-libraries in ETP-package of ASSETS-module imported successfully!\n",
      "All packages in utils ml timeseries RollingStats imported successfully!\n",
      "All functional SPARKNOSQLWLS-libraries in LOAD-package of ETL-module imported successfully!\n",
      "All functional EXECSESSION-libraries in SPARK-package of LIB-module imported successfully!\n",
      "All functional SPARKDBWLS-libraries in LOAD-package of ETL-module imported successfully!\n",
      "All functional SPARKCLEANNRICH-libraries in TRANSFORM-package of ETL-module imported successfully!\n",
      "sparkNoSQLwls Class initialization complete\n",
      "execSession Class initialization complete\n",
      "All functional DAILYTOPN-libraries in ETP-package of ASSETS-module imported successfully!\n",
      "sparkNoSQLwls Class initialization complete\n",
      "dailyTopN Class initialization complete\n",
      "performIndex Class initialization complete\n",
      "sparkNoSQLwls Class initialization complete\n",
      "\n",
      "Class initialization and load complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "sys.path.insert(1,\"/home/nuwan/workspace/rezaware/\")\n",
    "import rezaware as reza\n",
    "from mining.modules.assets.etp import performIndex as indx\n",
    "from utils.modules.etl.load import sparkDBwls as sdb\n",
    "from utils.modules.ml.timeseries import rollingstats as stats\n",
    "from utils.modules.etl.load import sparkNoSQLwls as nosql\n",
    "from utils.modules.lib.spark import execSession as spark\n",
    "\n",
    "''' restart initiate classes '''\n",
    "if debug:\n",
    "    import importlib\n",
    "    reza = importlib.reload(reza)\n",
    "    indx = importlib.reload(indx)\n",
    "    stats= importlib.reload(stats)\n",
    "    nosql= importlib.reload(nosql)\n",
    "    spark= importlib.reload(spark)\n",
    "    sdb = importlib.reload(sdb)\n",
    "    \n",
    "__desc__ = \"analyze crypto market capitalization time series data\"\n",
    "clsIndx =indx.Portfolio(desc=__desc__)\n",
    "# clsStat=stats.RollingStats(desc=__desc__)\n",
    "clsSDB = sdb.SQLWorkLoads(desc=__desc__)\n",
    "clsNoSQL=nosql.NoSQLWorkLoads(desc=__desc__)\n",
    "print(\"\\nClass initialization and load complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608794f1",
   "metadata": {},
   "source": [
    "## Read top N mcap assets from tip sql db\n",
    "\n",
    "Set the following parameters to select the mcap data from the database\n",
    "* ```_num_assets``` (integer) limits the number of asset count\n",
    "* ```_mcap_val_lb```(decimal) limits the asset selection by mcap_value\n",
    "* ```_date``` (datetime) selects assets with values for that day\n",
    "* ```_table```(string) by default is 'warehouse.mcap_past' where mcap daily data is stored\n",
    "\n",
    "Extends the ```utils/etl/load/sparkDBwls``` package to read the data from database table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518c74b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/22 20:16:52 WARN Utils: Your hostname, FarmRaiderTester resolves to a loopback address: 127.0.1.1; using 192.168.124.15 instead (on interface enp2s0)\n",
      "23/03/22 20:16:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/03/22 20:16:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/22 20:16:53 WARN FileSystem: Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem Unable to get public no-arg constructor\n",
      "23/03/22 20:16:53 WARN FileSystem: java.lang.NoClassDefFoundError: com/google/api/client/auth/oauth2/Credential\n",
      "23/03/22 20:16:53 WARN FileSystem: java.lang.ClassNotFoundException: com.google.api.client.auth.oauth2.Credential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/22 20:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/03/22 20:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected 3 assets \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " mcap_past_pk  | 19539                \n",
      " uuid          | 6397027b7cc473c58... \n",
      " data_source   | coingecko            \n",
      " asset_name    | btc                  \n",
      " asset_symbol  | btc                  \n",
      " mcap_date     | 2022-01-30 00:00:00  \n",
      " mcap_value    | 729084397823.3950... \n",
      " mcap_rank     | null                 \n",
      " created_dt    | 2023-02-14 12:07:... \n",
      " created_by    | farmraider           \n",
      " created_proc  | wrangler_assets_e... \n",
      " modified_dt   | 2023-02-21 14:45:... \n",
      " modified_by   | farmraider           \n",
      " modified_proc | utils_etl_load_sp... \n",
      " deactivate_dt | null                 \n",
      " log_ror       | 0.6966161566986901   \n",
      " simp_ror      | 0.0069020000000000   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_num_assets=3\n",
    "_mcap_val_lb=10000.0\n",
    "_date=datetime.strftime(date(2022,1,30),'%Y-%m-%dT00:00:00')\n",
    "_table='warehouse.mcap_past'\n",
    "kwargs={}\n",
    "\n",
    "_query =f\"select * from {_table} wmp where wmp.mcap_date = '{_date}' \" +\\\n",
    "        f\"and wmp.mcap_value > {_mcap_val_lb} \" +\\\n",
    "        f\"order by wmp.mcap_value DESC limit {_num_assets} \"\n",
    "\n",
    "_data = clsSDB.read_data_from_table(select=_query, **kwargs)\n",
    "print(\"selected %d assets \\n\" % _data.count())\n",
    "_data.show(n=1,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b9078",
   "metadata": {},
   "source": [
    "## Construct a dict with selected assets\n",
    "The dictionary serves as an input to the ```mining/modules/assets/etp/performIndex``` package to compuiting the index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87832e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'date': '2022-01-30T00:00:00',\n",
       "  'asset': 'btc',\n",
       "  'mcap.weight': 1.0,\n",
       "  'mcap.value': 729084397823.395},\n",
       " {'date': '2022-01-30T00:00:00',\n",
       "  'asset': 'bnb',\n",
       "  'mcap.weight': 1.0,\n",
       "  'mcap.value': 65455197964.9447},\n",
       " {'date': '2022-01-30T00:00:00',\n",
       "  'asset': 'avax',\n",
       "  'mcap.weight': 1.0,\n",
       "  'mcap.value': 17939687507.8046}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "_assets=_data.select(F.col('mcap_date'),\n",
    "                     F.col('asset_name'),\n",
    "                     F.col('mcap_value'))\\\n",
    "                .distinct()\n",
    "_portf=[]\n",
    "for _asset in _assets.collect():\n",
    "    _asset_dict={}\n",
    "    _asset_dict={\"date\" : datetime.strftime(_asset[0],'%Y-%m-%dT00:00:00'),\n",
    "                 \"asset\": _asset[1],\n",
    "                 'mcap.weight': 1.0,\n",
    "                 'mcap.value' : float(_asset[2]),\n",
    "                }\n",
    "    _portf.append(_asset_dict)\n",
    "_portf=sorted(_portf, key=lambda d: d['mcap.value'], reverse=True)\n",
    "_portf[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2422339",
   "metadata": {},
   "source": [
    "## Compute index values\n",
    "Set the parameters to compute the desired set of index measures\n",
    "* ```__idx_type__``` (list) typically 'adx','sharp','rsi','mfi','beta'\n",
    "* ```_coll_dt``` (date) the date, same as the date for which assets were selected\n",
    "* ```__val_col__``` (string) the column name with the mcap value\n",
    "* ```__name_col__```(string) the column name with the mcap asset names\n",
    "* ```__date_col__```(string) the column name with mcap date for which value was set\n",
    "* ```__rf_assets__``` (list) of 'risk free' assets to use as the baseline\n",
    "* ```__rf_val_col__``` (string) the column name with the mcap value\n",
    "* ```__rf_name_col__```(string) the column name with the mcap asset names\n",
    "* ```__rf_date_col__```(string) the column name with mcap date for which value was set\n",
    "\n",
    "The ```mining/modules/assets/etp/performIndex``` package will retrieve the index values for each of the assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44fc9d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset</th>\n",
       "      <th>adx</th>\n",
       "      <th>sharp</th>\n",
       "      <th>rsi</th>\n",
       "      <th>mfi</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>btc</td>\n",
       "      <td>0.088397</td>\n",
       "      <td>36.016989</td>\n",
       "      <td>0.451438</td>\n",
       "      <td>0.451438</td>\n",
       "      <td>0.868303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bnb</td>\n",
       "      <td>0.320226</td>\n",
       "      <td>34.996164</td>\n",
       "      <td>0.292148</td>\n",
       "      <td>0.292148</td>\n",
       "      <td>0.631958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avax</td>\n",
       "      <td>0.386210</td>\n",
       "      <td>20.929375</td>\n",
       "      <td>0.468284</td>\n",
       "      <td>0.468284</td>\n",
       "      <td>0.950068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset       adx      sharp       rsi       mfi      beta\n",
       "0   btc  0.088397  36.016989  0.451438  0.451438  0.868303\n",
       "0   bnb  0.320226  34.996164  0.292148  0.292148  0.631958\n",
       "0  avax  0.386210  20.929375  0.468284  0.468284  0.950068"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "__idx_type__=['adx','sharp','rsi','mfi','beta']\n",
    "_coll_dt=date(2022,1,30)\n",
    "__val_col__=\"simp_ror\"\n",
    "__name_col__='asset_name'\n",
    "__date_col__='mcap_date'\n",
    "__rf_assets__=['btc']\n",
    "__rf_val_col__=\"log_ror\"\n",
    "__rf_name_col__='asset_name'\n",
    "__rf_date_col__='mcap_date'\n",
    "_kwargs={\n",
    "    \"WINLENGTH\":7,\n",
    "    \"WINUNIT\":'DAY',\n",
    "}\n",
    "_res_df=pd.DataFrame()\n",
    "# _results=[]\n",
    "__idx_dict={}\n",
    "for asset_portf in _portf:\n",
    "    _idx_dict = clsIndx.get_index(\n",
    "        portfolio=[asset_portf],\n",
    "        asset_eval_date=_coll_dt,\n",
    "        asset_name_col=__name_col__,\n",
    "        asset_val_col =__val_col__,\n",
    "        asset_date_col=__date_col__,\n",
    "        index_type=__idx_type__,\n",
    "        risk_free_assets=__rf_assets__,\n",
    "        risk_free_name_col=__rf_name_col__,\n",
    "        risk_free_val_col=__rf_val_col__,\n",
    "        risk_free_date_col=__rf_date_col__,\n",
    "        **_kwargs,\n",
    "    )\n",
    "    _idx_dict['asset']=asset_portf['asset']\n",
    "    _res_df=pd.concat([_res_df,pd.DataFrame([_idx_dict])])\n",
    "_res_df.insert(0, 'asset', _res_df.pop('asset'))\n",
    "_res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9066d3a",
   "metadata": {},
   "source": [
    "## Dimensionality reduction techniques\n",
    "Review and select one\n",
    "* Principal Component Analysis (PCA) - [sampling adequacy](https://statistics.laerd.com/spss-tutorials/principal-components-analysis-pca-using-spss-statistics.php)\n",
    "* Generalized discriminant analysis (GDA)\n",
    "* Missing Values Ratio.\n",
    "* Low Variance Filter.\n",
    "* [Feature selection](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/) - unsupervised selection removing the target variable but dimensionality reduction is a replacement for unsupervised correlation based feature seelction.\n",
    "* Feature extraction - not into finding isoltated signals in the data\n",
    "* Non-negative matrix factorization (NMF) - we can normalize the data, which might be faster?\n",
    "* Linear discriminant analysis (LDA) - it's a supervised technique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e79508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
